# 多组学推理模型训练方案书

## 一、项目目标

* 构建一个 8B 模型，覆盖 **DNA、转录组、蛋白质** 三类模态任务。
* 设计 **约 10 个任务**：6 个单模态基础任务（如细胞注释、扰动预测、突变效应、蛋白功能分类等），4 个跨模态任务（DNA→RNA、Protein→Drug、RNA→Protein marker、通路描述↔表型）。
* 模型既要具备 **Chain-of-Thought (CoT) 推理习惯**，也要 **正确理解模态 token (<cell> <dna> <protein>) 的语义**。

---

## 二、数据构造策略

### 阶段 1：监督微调 (SFT)

* **目标**：学习格式、模态语义、基本任务模式。
* **数据来源**：自动生成的高质量 CoT 样本（仅正样本）。
* **规模建议**：

  * 单模态任务：每任务 **1–1.5 万条**
  * 跨模态任务：每任务 **1.5–2.5 万条**
  * **总量：15–20 万条**（平均 600 tok/条，约 0.9–1.2 亿 tok）

### 阶段 2：强化学习 (GRPO)

* **目标**：引导模型偏好「中等长度 CoT」+「正确指令遵循」。
* **数据构造**：

  1. **CoT 长度对比**：每个问题生成 5 个版本（最短/最长 reward 低，中间 reward 高）。
  2. **指令遵循对比**：通过提示词工程生成「正确遵循模态 token」与「错误当作文本」的不同质量数据。
* **规模建议**：

  * 单模态任务：每任务 **2–3 千组 prompt**
  * 跨模态任务：每任务 **4–5 千组 prompt**
  * **总量：3–4 万组 prompt**（每组 3–5 候选，平均 600 tok/候选，约 0.7–1 亿 tok）

---

## 三、训练流程

1. **SFT 阶段**

   * 模式：全量微调或 QLoRA（推荐 QLoRA 节省成本）。
   * 目标：让模型掌握「先 reasoning → 再 answer」的习惯，并理解 `<cell>` `<dna>` `<protein>` 等符号。

2. **GRPO 阶段**

   * 奖励函数：

     * 答案正确性 (+1/-1)
     * CoT 长度趋势（U 型：最短/最长低分，中间高分）
     * 模态 token 遵循（正确高分，错误低分）
   * 目标：强化模型「倾向于推理」+「模态指令遵循」。

3. **评估与迭代**

   * 先用小规模数据（每任务 5k SFT / 1k RL）快速验证收敛，再扩量。
   * 评估维度：任务准确率、推理长度分布、模态 token 使用情况。

---

## 四、资源与成本预算

* **硬件**：A100 (80G)，¥2/h（单卡价）。

* **SFT 阶段**

  * 15–20 万条，0.9–1.2 亿 tok
  * QLoRA 吞吐 ~3–6k tok/s → **4–11 小时**
  * **费用：¥8–22**

* **GRPO 阶段**

  * 3–4 万组 prompt × 4 候选 × 600 tok ≈ 0.7–1 亿 tok
  * 生成 + 更新 ≈ 170–220 小时
  * **费用：¥340–¥440**

* **总成本**

  * 典型配置：**¥350–¥500**
  * 重载配置（2 epoch、5 候选、长推理）：**¥1.5k–¥2k**
  * 多卡并行：**时间缩短，总价近似不变**。

---

## 五、总结

* **SFT**：用正样本「一股脑微调」，打好格式与任务基础。
* **GRPO**：通过「长度对比 + 指令遵循对比」构造 reward，引导模型推理习惯。
* **数据量**：SFT ~20 万条，GRPO ~4 万组即可；**质量 > 数量**。
* **成本**：典型场景仅需 **¥500 左右**，重载也在几千元以内。